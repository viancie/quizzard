Topic	Subtopic	Description	References	isBookmarked
History	The Agricultural Revolution	The agricultural revolution is the name given to a number of cultural transformations that initially allowed humans to change from a hunting and gathering subsistence to one of agriculture and animal domestications. Today, more than 80% of human worldwide diet is produced from less than a dozen crop species many of which were domesticated many years ago. Scientists study ancient remains, bone artifacts, and DNA to explore the past and present impact of plant and animal domestication and to make sense of the motivations behind early cultivation techniques. Archeological evidence illustrates that starting in the Holocene epoch approximately 12 thousand years ago (kya), the domestication of plants and animals developed in separate global locations most likely triggered by climate change and local population increases. This transition from hunting and gathering to agriculture occurred very slowly as humans selected crops for cultivation, animals for domestication, then continued to select plants and animals for desirable traits. The development of agriculture marks a major turning point in human history and evolution. In several independent domestication centers, cultivation of plants and animals flourished according to the particular environmental conditions of the region, whereas human migration and trade propelled the global spread of agriculture. This change in subsistence provided surplus plant food that accumulated during the summer and fall for storage and winter consumption, as well as domesticated animals that could be used for meat and dairy products throughout the year. Because these new survival strategies no longer required relocation and migration in search of food, humans were able to establish homesteads, towns, and communities, which, in turn, caused rapid increases in population densities and lead to the emergence of civilizations. This dependence on plant and animal domestication entailed a number of other environmental adaptations including deforestation, irrigation, and the allocation of land for specific crop cultivation. It also triggered various other innovations including new tool technologies, commerce, architecture, an intensified division of labor, defined socioeconomic roles, property ownership, and tiered political systems. This shift in subsistence mode provided a relatively safer existence and in general more leisure time for analytical and creative pursuits resulting in complex language development, and the accelerated evolution of art, religion, and science. However, increases in population density also correlated with the increased prevalence of diseases, interpersonal conflicts, and extreme social stratification. The rise of agriculture and the influence of genetics and culture (gene–culture coevolution) continue to affect modern humans through alterations in nutrition, predisposition to obesity, and exposure to new diseases. This chapter will cover the various regions that adopted early agricultural practices and look at the long-term positive and negative effects of agriculture on society.	B. L. Turner II, "The Agricultural Revolution in Prehistory: Why Did Foragers Become Farmers?" (2002).	TRUE
History	Th Development of Writing 	The development of writing is a pivotal milestone in human history, marking the transition from prehistoric oral communication to the recording and preservation of information. The earliest known writing systems emerged around 3500 BCE in ancient Mesopotamia, with the Sumerians employing cuneiform script on clay tablets. Subsequent civilizations, such as the Egyptians, Indus Valley, and Chinese, independently devised their own writing systems, each with unique characters and symbols. The advent of writing revolutionized societal organization, enabling the documentation of laws, religious texts, and cultural achievements. Notable references to this profound advancement include the Code of Hammurabi, the Egyptian hieroglyphs on monumental structures, and the ancient Chinese oracle bone inscriptions. The development of writing laid the foundation for the accumulation and dissemination of knowledge, fostering the growth of civilizations and facilitating the transmission of culture across generations. This transformative leap in human communication has left an indelible mark on the evolution of language and the progress of civilizations throughout history.	Nissen, H. J., Damerow, P., & Englund, R. K. (1993). Archaic Bookkeeping: Early Writing and Techniques of Economic Administration in the Ancient Near East. University of Chicago Press.	FALSE
History	The Age of Exploration	The Age of Exploration, also known as the Age of Discovery, spanned from the late 15th century to the early 17th century and was characterized by European maritime exploration that led to the discovery of new routes, continents, and cultures. Motivated by a desire for wealth, trade, and the spread of Christianity, European powers such as Portugal, Spain, England, and the Netherlands sponsored voyages across the Atlantic and around Africa, seeking new trade routes to Asia. Christopher Columbus's 1492 voyage to the Americas, Vasco da Gama's circumnavigation of Africa to reach India in 1498, and Ferdinand Magellan's 1519-1522 expedition, which circumnavigated the globe, are notable examples. The Age of Exploration had profound global implications, shaping the modern world through cultural exchanges, the Columbian Exchange of goods and ideas, and the establishment of colonial empires.	 Boxer, C. R. (1991). The Portuguese Seaborne Empire 1415–1825. Hutchinson.	FALSE
History	The Industrial Revolution 	The Industrial Revolution was a period of profound economic, technological, and social transformation that originated in Britain in the late 18th century and spread to other parts of the world during the 19th and early 20th centuries. Characterized by the shift from agrarian and manual labor-based economies to industrial and machine-driven production, the revolution brought about significant advancements in manufacturing, transportation, and communication. Key innovations such as the steam engine, mechanized textile production, and the development of railways played pivotal roles in fostering unprecedented economic growth. While it led to increased productivity, urbanization, and the rise of capitalism, the Industrial Revolution also brought about significant social challenges, including labor exploitation, poor working conditions, and social inequality. This transformative period laid the foundation for the modern industrialized world. 	Mokyr, J. (1999). The Second Industrial Revolution, 1840-1914. Routledge	FALSE
History	World War I	World War I, also known as the Great War, was a global conflict that lasted from 1914 to 1918, involving many of the world's great powers. Triggered by the assassination of Archduke Franz Ferdinand of Austria-Hungary in 1914, the war quickly escalated as alliances were activated, drawing in major European nations and eventually expanding to involve countries across the globe. The conflict featured trench warfare, technological innovations like machine guns and chemical weapons, and resulted in widespread devastation and loss of life. The Treaty of Versailles in 1919 formally ended the war, imposing heavy reparations on Germany and reshaping the geopolitical landscape. World War I had profound and lasting effects on the course of history, setting the stage for future conflicts and influencing political and social developments in the 20th century.	Hewitson, Mark. "Germany and the Causes of the First World War: Historical Debate." Journal of Contemporary History, vol. 51, no. 1, 2016, pp. 101-118. DOI: 10.1177/0022009415606974.	FALSE
History	World War II	World War II, spanning from 1939 to 1945, was a multifaceted global conflict with roots in the aftermath of World War I and the interwar period. Adolf Hitler's aggressive expansionist policies, including the annexation of Austria and Czechoslovakia, eventually led to the invasion of Poland in 1939, marking the formal start of the war. The conflict involved major theaters of operation in Europe, Asia, and Africa, with significant battles such as Stalingrad, Normandy, and the Battle of the Bulge. The war witnessed the Holocaust, in which six million Jews were systematically murdered by the Nazis. The Pacific War saw intense island-hopping campaigns and concluded with the Allied victory after the atomic bombings of Hiroshima and Nagasaki. The war's aftermath saw the establishment of the United Nations and the beginning of the Cold War between the United States and the Soviet Union. World War II had profound and lasting impacts on technology, diplomacy, and the post-war order.	Beevor, A. (2012). The Second World War. Little, Brown and Company.	FALSE
History	Cold War	The Cold War was a geopolitical tension and ideological struggle between the United States and its Western allies, and the Soviet Union and its Eastern Bloc counterparts, lasting from the end of World War II in 1945 until the collapse of the Soviet Union in 1991. Characterized by a lack of direct military conflict between the two superpowers, the Cold War was marked by intense competition and hostility, with each side seeking to expand its influence globally. The conflict played out in various arenas, including proxy wars, nuclear arms races, and ideological confrontations. The Cuban Missile Crisis in 1962 and the construction of the Berlin Wall in 1961 were critical moments during this period, highlighting the potential for nuclear conflict and the division of Europe. The Cold War had profound implications for international relations, shaping the global balance of power and influencing the formation of alliances and international organizations.	Gaddis, J. L. (2005). The Cold War: A New History. Penguin Books.	FALSE
History	The Information Age	The Information Age, also known as the Digital Age, refers to the period in human history characterized by the rapid proliferation of information and communication technologies (ICTs). This era, often considered to have begun in the late 20th century, has witnessed a profound societal transformation driven by the advent of computers, the internet, and digital communication tools. The Technological Revolution, a central component of the Information Age, encompasses the rapid and unprecedented advancements in technology, reshaping various facets of human life, including communication, commerce, education, and governance. This era has seen the rise of interconnected global networks, enabling instantaneous information exchange and facilitating the digitization of various industries. The ongoing impact of the Information Age and Technological Revolution continues to shape the way individuals interact, businesses operate, and societies evolve.	Castells, M. (1996). The Rise of the Network Society. The Information Age: Economy, Society and Culture (Vol. I). Blackwell.	FALSE
History	The Philippine Revolution	The Philippine Revolution, also known as the Katipunan Revolution, was a series of armed conflicts that took place between 1896 and 1898 in the Philippines. It marked the culmination of decades of resistance against Spanish colonial rule and was ignited by the secret society Katipunan, led by Filipino nationalists such as Andres Bonifacio and Emilio Aguinaldo. The revolution aimed to achieve Philippine independence and end over three centuries of Spanish colonization. Battles were fought across the archipelago, with notable events including the Siege of Baler and the Battle of Manila Bay. The conflict eventually led to the establishment of the First Philippine Republic on June 12, 1898, though the Philippines later fell under American rule after the Spanish-American War. The Philippine Revolution played a crucial role in shaping the nation's history and fostering a sense of national identity.	Agoncillo, T. (1990). "Malolos: The Crisis of the Republic." University of the Philippines Press.	FALSE
History	Covid-19 Pandemic	The COVID-19 era, characterized by the global pandemic caused by the novel coronavirus SARS-CoV-2, has significantly impacted societies worldwide, reshaping daily life, healthcare systems, and economic structures. Beginning in late 2019, the virus spread rapidly, leading to widespread illness, unprecedented public health measures such as lockdowns and social distancing, and an accelerated focus on vaccine development. The pandemic underscored the importance of international collaboration in addressing global health crises and highlighted disparities in healthcare access. Research has played a crucial role in understanding the virus, developing diagnostics and treatments, and guiding public health responses. The COVID-19 era has left a lasting imprint on the world, influencing discussions on preparedness for future pandemics, the role of science in policy-making, and the need for resilient healthcare systems.	World Health Organization (WHO). (2022). Coronavirus (COVID-19) Dashboard. Retrieved from https://covid19.who.int/	FALSE
Chemistry	Atomic Structure	Atomic structure is a foundational concept in chemistry that explores the organization of atoms, the building blocks of matter. At its core, atomic structure entails the arrangement of subatomic particles within an atom—electrons orbiting the nucleus composed of protons and neutrons. Electrons, with a negative charge, occupy distinct energy levels or shells around the nucleus, and their interactions govern chemical bonding and reactivity. The nucleus, in turn, houses positively charged protons and electrically neutral neutrons. The number of protons in an atom defines its atomic number, determining its elemental identity on the periodic table. Neutrons contribute to the atom's mass without influencing its chemical properties. The understanding of atomic structure has evolved significantly through experimental evidence and theoretical models, with contributions from pioneers like J.J. Thomson, Ernest Rutherford, and Niels Bohr, leading to the development of quantum mechanics. This knowledge forms the basis for comprehending the behavior of matter at the molecular and macroscopic levels.	Rutherford, E. (1911). "The Scattering of α and β Particles by Matter and the Structure of the Atom." Philosophical Magazine, 21(125), 669–688. doi:10.1080/14786440508637080	FALSE
Chemistry	Chemical Bonding	Chemical bonding is a fundamental concept in chemistry that elucidates how atoms interact and combine to form molecules. The bonding between atoms is driven by the desire to achieve a stable and lower energy state. There are three main types of chemical bonds: covalent, ionic, and metallic. Covalent bonds involve the sharing of electrons between atoms, typically occurring between nonmetals. Ionic bonds result from the transfer of electrons from one atom to another, leading to the formation of charged ions. Metallic bonds, prevalent in metals, arise from the delocalized sharing of electrons throughout a metal lattice. Understanding chemical bonding is crucial for predicting the properties of substances, explaining reactivity, and designing new materials. This concept serves as a cornerstone for various branches of chemistry, influencing research in fields ranging from materials science to biochemistry.	Pauling, L. (1960). The Nature of the Chemical Bond. Cornell University Press.	FALSE
Chemistry	Periodic Table and Periodicity	The Periodic Table is a fundamental tool in chemistry that organizes elements based on their atomic number, electron configuration, and chemical properties. Developed by Dmitri Mendeleev and later refined by others, the table displays a systematic arrangement of elements in rows and columns, highlighting periodic trends in properties such as atomic radius, ionization energy, and electronegativity. The periodicity observed in the table arises from the repeating patterns of electron filling in the atomic shells. Elements within the same group often share similar chemical behavior due to their comparable electron configurations. The Periodic Table serves as a concise and powerful reference, facilitating the prediction of an element's properties and its interactions with other elements. The continuous expansion and refinement of the Periodic Table contribute to ongoing advancements in our understanding of the relationships between different elements.	Mendeleev, D. (1869). "The Dependence between the Properties of the Atomic Weights of the Elements." Journal of the Russian Chemical Society, 1(1), 60-77.	FALSE
Chemistry	Stoichiometry	Stoichiometry is a fundamental concept in chemistry that involves the quantitative relationships between reactants and products in chemical reactions. It enables the calculation of the amounts of substances consumed and produced during a chemical reaction based on the balanced chemical equation. The term originates from the Greek words "stoicheion," meaning element, and "metron," meaning measure. Stoichiometric calculations allow chemists to determine the ideal ratios of reactants for a given reaction and predict the amounts of products formed. This concept is essential in understanding and optimizing chemical processes, whether in a laboratory setting or industrial production. It plays a crucial role in fields such as chemical engineering, environmental science, and materials science, providing a quantitative foundation for chemical analysis and synthesis.	Zumdahl, S. S., & Zumdahl, S. L. (2014). Chemistry. Cengage Learning.	FALSE
Chemistry	Thermodynamics	Thermodynamics is a branch of physical chemistry that deals with the study of energy and its transformations in chemical and physical processes. It encompasses a set of principles and laws governing the relationships between heat, work, and the properties of systems. The first and second laws of thermodynamics are foundational concepts, with the former stating that energy is conserved in a closed system, while the latter introduces the concept of entropy and the directionality of natural processes. Thermodynamics plays a crucial role in understanding and predicting the behavior of chemical reactions, phase transitions, and various physical phenomena. The field has broad applications, ranging from engineering and physics to biology and environmental science, making it an indispensable tool for comprehending and manipulating energy changes in diverse systems.	Smith, J. D., van Ness, H. C., & Abbott, M. M. (2005). Introduction to Chemical Engineering Thermodynamics. McGraw-Hill Education.	FALSE
Chemistry	Acids and Bases	Acids and bases are fundamental concepts in chemistry, representing classes of substances with distinct properties and behaviors. Acids are substances that can donate protons (H⁺ ions), while bases are substances that can accept protons. The pH scale is commonly used to quantify the acidity or basicity of a solution, ranging from 0 (highly acidic) to 14 (highly basic), with 7 considered neutral. Acids and bases play crucial roles in various chemical reactions and biological processes. The understanding of acid-base chemistry extends to applications in fields such as environmental science, medicine, and industry, influencing phenomena from the behavior of household substances to the regulation of physiological functions.	Masterton, W. L., & Hurley, C. N. (2014). Chemistry: Principles and Reactions. Cengage Learning.	FALSE
Chemistry	Chemical Kinetics	Chemical kinetics is the branch of chemistry that focuses on the study of reaction rates and mechanisms, providing insights into the speed at which chemical reactions occur and the factors influencing their progress. It involves the examination of how reactants transform into products over time, elucidating the pathways and intermediates involved in the process. Key concepts in chemical kinetics include reaction rates, rate laws, reaction mechanisms, and the factors affecting reaction rates, such as temperature, concentration, and catalysts. This field plays a crucial role in various applications, ranging from optimizing industrial processes to understanding biological reactions. Moreover, insights gained from chemical kinetics contribute to the development of efficient and sustainable chemical reactions. Researchers in this area employ experimental techniques and theoretical models to unravel the intricate details of reaction dynamics and to design reactions with desired kinetics for practical applications.	Tro, N. J. (2017). "Chemical Kinetics." In Chemistry: A Molecular Approach (4th ed., pp. 607-649). Pearson.	FALSE
Chemistry	Organic Chemistry	Organic Chemistry is a branch of chemistry that focuses on the study of carbon-containing compounds, which play a central role in the chemistry of life. It explores the structure, properties, reactions, and synthesis of organic molecules, encompassing a wide range of compounds from simple hydrocarbons to complex biomolecules like proteins and nucleic acids. Understanding organic chemistry is crucial for various scientific disciplines, including medicine, biochemistry, and materials science. Researchers in organic chemistry investigate mechanisms of reactions, design new synthetic routes, and develop strategies for the efficient synthesis of complex molecules. The field has evolved significantly over the years, with applications ranging from pharmaceuticals to polymers. Organic chemistry provides the tools and insights necessary for the development of novel materials and the discovery of new drugs, making it an essential discipline in the broader landscape of chemical sciences.	Clayden, J., Greeves, N., & Warren, S. (2012). Organic Chemistry. Oxford University Press.	FALSE
Chemistry	Biochemistry	Biochemistry is the branch of science that explores the chemical processes and substances occurring within living organisms. It delves into the molecular mechanisms underlying various biological functions, including the structure and function of biomolecules such as proteins, nucleic acids, lipids, and carbohydrates. Biochemists seek to understand how these molecules interact and contribute to essential processes like metabolism, signal transduction, and genetic expression. The field plays a pivotal role in elucidating the molecular basis of diseases and in the development of pharmaceuticals and medical treatments. By deciphering the intricate chemical language of life, biochemistry provides invaluable insights into the complexity of living systems.	Nelson, D.L., & Cox, M.M. (2017). Lehninger Principles of Biochemistry. 7th edition. W. H. Freeman.	FALSE
Chemistry	Analytical Chemistry	Analytical Chemistry is a branch of chemistry that focuses on the identification and quantification of substances within a sample. It encompasses a diverse range of techniques and methods used to determine the composition of matter, including spectroscopy, chromatography, and electrochemical analysis. Analytical chemists employ these tools to investigate the presence and concentration of specific compounds, often playing a crucial role in quality control, environmental monitoring, and forensic analysis. The field continually evolves with advancements in instrumentation and technology, allowing for increased sensitivity and precision in measurements. Researchers in analytical chemistry contribute significantly to various scientific and industrial endeavors, providing essential insights into the composition of materials in fields such as pharmaceuticals, food and beverage, and environmental science.	Skoog, D. A., Holler, F. J., & Crouch, S. R. (2017). Principles of Instrumental Analysis. Cengage Learning.	FALSE
Computer Science	Data Structures and Algorithms	Algorithms and data structures form the backbone of computer science, providing essential tools for solving problems and organizing information efficiently. A data structure is a method of organizing data in a virtual system. Think of sequences of numbers, or tables of data: these are both well-defined data structures. Data structures provide frameworks for organizing and storing data in computer systems. One example is an Array, a simple and widely-used data structure that stores elements in contiguous memory locations. Linked Lists represent a dynamic data structure where elements are connected by pointers, allowing for efficient insertions and deletions. Stacks and Queues, both linear data structures, follow the Last In, First Out (LIFO) and First In, First Out (FIFO) principles, respectively. Trees, such as Binary Trees, organize data hierarchically, while Graphs represent relationships between entities. These data structures, like arrays for efficient storage or trees for hierarchical representation, are fundamental tools in computer science, influencing the design and performance of algorithms in diverse applications. An algorithm is a sequence of steps executed by a computer that takes an input and transforms it into a target output.Algorithms are systematic and well-defined sets of instructions designed to accomplish specific tasks or solve particular problems. One example is the QuickSort algorithm, a sorting algorithm that employs a divide-and-conquer approach. It efficiently sorts an array by recursively dividing it into smaller sub-arrays, sorting them, and then merging them to produce the final sorted array. Another example is Binary Search, a searching algorithm particularly effective on sorted arrays. It repeatedly divides the search interval, efficiently narrowing down the potential locations for a target element. Algorithms like Depth-First Search are essential for graph traversal, exploring branches as far as possible before backtracking. These algorithmic procedures are foundational in computer science, optimizing processes in tasks such as sorting, searching, and graph analysis. Together, data structures and algorithms combine and allow programmers to build whatever computer programs they’d like. Deep study into data structures and algorithms ensures well-optimized and efficient code.	Gupta, S. (2023, September 1). What Are Data Structures and Algorithms? Springboard Blog. https://www.springboard.com/blog/software-engineering/data-structures-and-algorithms/#:~:text=A%20data%20structure%20is%20a,it%20into%20a%20target%20output.	FALSE
Computer Science	Software Engineering	Software Engineering is a multifaceted discipline essential for software development, demanding proficiency in problem-solving, algorithm design, coding, testing, debugging, and continual learning. Problem-solving in involves breaking down complex tasks into smaller, more manageable components. It's about understanding the requirements of a problem, identifying potential solutions, and choosing the most appropriate approach. Algorithm design is the process of creating clear and efficient step-by-step procedures to solve specific problems. It's about devising a plan or set of instructions that a computer can follow to accomplish a given task. Coding is the process of translating devised solutions and algorithms into executable code using programming languages. It requires a deep understanding of syntax, logical structures, and adherence to best practices for code readability and maintainability. Coding transforms abstract ideas into tangible software. Testing is a critical phase where the developed code is systematically evaluated against predefined test cases. The goal is to verify that the program functions as intended and produces the expected outputs. Rigorous testing is integral to identifying discrepancies between expected and actual outcomes, allowing for iterative improvements. Debugging is the process of identifying and resolving errors or bugs in the code. It involves using debugging tools to trace the execution flow, understand error messages, and isolate issues. Continual learning is the ongoing process of staying updated with new programming languages, tools, and best practices. It acknowledges the dynamic nature of the field and emphasizes the importance of adapting to evolving technologies. Programmers engage in continual learning to enhance their skills and remain relevant in the ever-changing landscape of programming.	McConnell, S. (2004). Code Complete: A Practical Handbook of Software Construction (2nd ed.). Microsoft Press.	FALSE
Computer Science	Computer Architecture	Computer architecture is like the master plan that outlines how a computer is built and operates. It involves designing the structure and interaction of its essential components, including the Central Processing Unit or CPU, memory, input/output systems, and the pathways that allow them to communicate. This blueprint determines how information is processed, stored, and retrieved within the computer system. Computer architecture is like the master plan that outlines how a computer is built and operates. It involves designing the structure and interaction of its essential components, including the brain or CPU, memory, input/output systems, and the pathways that allow them to communicate. This blueprint determines how information is processed, stored, and retrieved within the computer system. An example of computer architecture is the von Neumann architecture, named after mathematician and computer scientist John von Neumann. In this design, the computer uses a single memory space for both storing instructions (the steps a computer follows) and data (the information it works with). This architecture follows a sequential process: fetch an instruction from memory, decode it, execute the operation, and then store the result back in memory. The von Neumann architecture is foundational and has been widely adopted in various computer systems. Understanding computer architecture is crucial for computer scientists and engineers as it provides insights into how to optimize a computer's performance. Different architectures, like the von Neumann example, offer various trade-offs in terms of simplicity, speed, and efficiency, influencing the design choices made in creating computers for different purposes.	Hennessy, J. L., & Patterson, D. A. (2017). Computer Architecture: A Quantitative Approach. Morgan Kaufmann.	FALSE
Computer Science	Artificial Intelligence	Artificial Intelligence (AI) is a field of computer science focused on creating intelligent systems that can perform tasks that typically require human intelligence. These tasks include learning from experience, understanding natural language, recognizing patterns, solving problems, and making decisions. Unlike traditional computer programs, AI systems are designed to adapt and improve over time, learning from data and refining their performance through experience. Key insights in AI include machine learning, where algorithms enable systems to learn and improve without explicit programming, and neural networks, which mimic the human brain's structure to enhance pattern recognition. Natural Language Processing (NLP) is another aspect of AI that enables computers to understand and interpret human language, facilitating applications like chatbots and language translation. AI has diverse use cases across various industries. In healthcare, AI is employed for diagnostics and personalized treatment plans. In finance, it aids in fraud detection and algorithmic trading. Autonomous vehicles leverage AI for navigation and decision-making. Virtual assistants like Siri and Alexa exemplify AI in enhancing human-computer interactions. The ethical considerations and responsible deployment of AI are increasingly important topics. Ensuring fairness, transparency, and accountability in AI systems is crucial to mitigate biases and potential risks associated with their widespread adoption. Overall, AI holds the promise of revolutionizing industries and improving our daily lives, but its development requires careful consideration of ethical implications and continuous advancements in technology.	Russell, S., & Norvig, P. (2021). Artificial Intelligence: A Modern Approach (4th ed.). Pearson.	FALSE
Computer Science	Machine Learning	Machine Learning is like teaching computers to learn and make decisions without being explicitly programmed. It involves developing algorithms that enable systems to recognize patterns in data and improve their performance over time. Instead of giving computers detailed instructions, we provide them with examples and let them learn from experience. A helpful analogy is teaching a computer to recognize cats by showing it various pictures of cats until it learns to identify them on its own. In machine learning, key insights include supervised learning, where the system is trained on labeled data, and unsupervised learning, where the algorithm learns from unlabeled data to find hidden patterns. Reinforcement learning involves training models to make sequences of decisions, and deep learning uses neural networks to process complex data. Use cases range from image and speech recognition to recommendation systems, fraud detection, and autonomous vehicles. The ethical considerations surrounding bias and transparency in machine learning models are crucial for responsible deployment and continued advancements in this rapidly evolving field.	Ng, A. (2018). Machine Learning Yearning. deeplearning.ai.	FALSE
Computer Science	Data Science and Big Data	Data Science is like a detective for information in the digital world. It's all about collecting a bunch of information, analyzing it, and finding important details to help make smart decisions. Imagine you have a puzzle made of data, and data scientists are the ones who put the pieces together to reveal the big picture. They use various tools and techniques to explore data and uncover valuable knowledge. For example, in business, data science can help understand customer preferences or predict trends to make better decisions. Big Data is like handling a massive library of information, way too big and complex for regular methods to manage. It's about dealing with enormous amounts of data, processing it quickly, and handling different types of information.  It's not just about having a lot of data; it's also about how fast it comes in and how different the pieces are. For instance, in technology and industry, Big Data helps manage huge datasets, like analyzing user behavior on websites or predicting equipment failures in factories. Key insights in Data Science involve using statistical methods, machine learning algorithms, and visualizing data patterns to gain meaningful insights. In business, it helps with customer segmentation, personalized marketing, and operational efficiency. On the other hand, Big Data applications are vast, from predicting disease outbreaks in healthcare to optimizing transportation systems and analyzing social media trends. Ensuring ethical use, especially regarding privacy and bias, is critical in both Data Science and Big Data applications to maintain fairness and responsibility in handling information.	Provost, F., & Fawcett, T. (2013). Data Science for Business. O'Reilly Media, Inc.	FALSE
Computer Science	Computer Networks	Computer Networks are like digital highways that allow devices such as computers, smartphones, and tablets to talk to each other. Imagine a vast interconnected system of roads for information, enabling data to travel between devices. These networks facilitate communication and the sharing of resources, making it possible for people to access the internet and connect with others globally. Understanding computer networks involves grasping how data moves through these digital pathways, ensuring smooth communication and information exchange. Computer networks encompass understanding protocols like TCP/IP, the backbone of internet communication. Protocols dictate how data is transmitted between devices. Use cases range from simple home networks for sharing files to complex global networks that power internet services. The efficiency and security of data transmission in computer networks are critical considerations, impacting everything from everyday internet browsing to large-scale business operations.	Kurose, J. F., & Ross, K. W. (2016). Computer Networking: A Top-Down Approach. Pearson.	FALSE
Computer Science	Information Security	Information Security is the digital guardian that protects sensitive information from unauthorized access, alteration, or damage. It involves implementing measures to ensure that data, whether stored or transmitted, remains confidential, intact, and available only to those with proper authorization. Think of it as creating a secure fortress for digital information, safeguarding it against potential threats. A foundational concept in the field is the CIA triad, emphasizing Confidentiality, Integrity, and Availability. Information security include encryption techniques to protect data confidentiality, integrity checks to ensure data remains unaltered, and access controls to manage who can interact with sensitive information. Use cases span from securing personal data on a computer or smartphone to protecting sensitive corporate information and financial transactions. The evolving landscape of cyber threats requires continuous updates to security measures, making information security an ongoing and critical aspect of digital safety.	Pfleeger, C. P., & Pfleeger, S. L. (2015). Security in Computing. Pearson.	FALSE
Computer Science	Database Systems	Database Systems are like organized digital filing cabinets where information is stored, managed, and accessed efficiently. They serve as structured collections of data, allowing users to store, retrieve, and manipulate information. Think of it as a well-organized library catalog that helps find and manage books easily. These systems use specialized software to organize data into tables, making it easier to search and extract specific information when needed. Database systems include different models like relational databases, which organize data into tables with relationships between them, and NoSQL databases designed for handling large and unstructured datasets efficiently. Use cases range from managing customer information in businesses to storing and retrieving data in web applications. Database systems play a crucial role in various industries, ensuring data organization, accuracy, and accessibility while supporting efficient information retrieval and analysis.	Coronel, C., & Morris, S. (2015). Database Systems: Design, Implementation, & Management. Cengage Learning.	FALSE
Computer Science	Human-Computer Interaction	Human-Computer Interaction (HCI) is all about making the conversation between people and computers smooth and friendly. Imagine it as creating a language that both humans and computers understand effortlessly. HCI involves designing interfaces, like buttons and menus, in a way that people can easily grasp and use without confusion. It's about understanding how people think and behave when using technology and designing interfaces that are intuitive, clear, and provide feedback.  HCI focus on simplicity and efficiency in design, ensuring that technology interactions are not only functional but also enjoyable. Use cases of HCI are prevalent in our daily lives, from designing user-friendly websites and applications to creating intuitive digital devices. In essence, HCI strives to enhance the overall experience of interacting with technology by making it user-centric and accessible.	Cooper, A., Reimann, R., & Cronin, D. (2007). About Face 3: The Essentials of Interaction Design. Wiley.	FALSE